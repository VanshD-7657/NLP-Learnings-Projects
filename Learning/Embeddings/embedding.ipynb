{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a01cace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74b94c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [\"the glass of milk\",\n",
    "        \"the glass of juice\",\n",
    "        \"the cup of tea\",\n",
    "        \"I am a good boy\",\n",
    "        \"I am a good developer\",\n",
    "        \"understand the meaning of words\",\n",
    "        \"your videos are good\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the vacubalary size\n",
    "voc_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9917, 6216, 1029, 5327],\n",
       " [9917, 6216, 1029, 5769],\n",
       " [9917, 1165, 1029, 2026],\n",
       " [5848, 6567, 4873, 1763, 5701],\n",
       " [5848, 6567, 4873, 1763, 4466],\n",
       " [582, 9917, 1082, 1029, 7291],\n",
       " [8564, 8416, 6779, 1763]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot Representation\n",
    "one_hot_rep = [one_hot(words,voc_size) for words in sent]\n",
    "one_hot_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9241ab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word Embedding Representation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0 9917 6216 1029 5327]\n",
      " [   0    0    0    0 9917 6216 1029 5769]\n",
      " [   0    0    0    0 9917 1165 1029 2026]\n",
      " [   0    0    0 5848 6567 4873 1763 5701]\n",
      " [   0    0    0 5848 6567 4873 1763 4466]\n",
      " [   0    0    0  582 9917 1082 1029 7291]\n",
      " [   0    0    0    0 8564 8416 6779 1763]]\n"
     ]
    }
   ],
   "source": [
    "sent_length = 8\n",
    "embedded_docs = pad_sequences(one_hot_rep, padding=\"pre\",maxlen = sent_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AMAN\\miniconda3\\envs\\tfenv\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Feature Representation\n",
    "dim = 10\n",
    "model = Sequential()\n",
    "model.add(Embedding(voc_size,dim,input_length=sent_length))\n",
    "model.compile(\"adam\",\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd2ef56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.01965251,  0.03135104,  0.01402876,  0.01379016,\n",
       "         -0.03591919, -0.01205577,  0.00141083, -0.02327669,\n",
       "         -0.04379898, -0.04719068],\n",
       "        [-0.02825204,  0.01457674,  0.00036437,  0.0441901 ,\n",
       "          0.03212296, -0.03848406,  0.04848189, -0.0336314 ,\n",
       "          0.02269825, -0.03881244],\n",
       "        [ 0.0315528 , -0.03684436, -0.02680424,  0.00198674,\n",
       "         -0.025009  , -0.02826208,  0.03172994,  0.02685961,\n",
       "          0.01890923,  0.02135355],\n",
       "        [ 0.03876119,  0.02237042,  0.02382977, -0.03579959,\n",
       "          0.04280735, -0.00099518,  0.02244296, -0.0286389 ,\n",
       "         -0.01909524,  0.00037252]],\n",
       "\n",
       "       [[-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.01965251,  0.03135104,  0.01402876,  0.01379016,\n",
       "         -0.03591919, -0.01205577,  0.00141083, -0.02327669,\n",
       "         -0.04379898, -0.04719068],\n",
       "        [-0.02825204,  0.01457674,  0.00036437,  0.0441901 ,\n",
       "          0.03212296, -0.03848406,  0.04848189, -0.0336314 ,\n",
       "          0.02269825, -0.03881244],\n",
       "        [ 0.0315528 , -0.03684436, -0.02680424,  0.00198674,\n",
       "         -0.025009  , -0.02826208,  0.03172994,  0.02685961,\n",
       "          0.01890923,  0.02135355],\n",
       "        [-0.0235813 , -0.04398675, -0.01745636,  0.02743511,\n",
       "         -0.04830014, -0.02398262,  0.02674537, -0.00671796,\n",
       "         -0.02098477,  0.02330071]],\n",
       "\n",
       "       [[-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.01965251,  0.03135104,  0.01402876,  0.01379016,\n",
       "         -0.03591919, -0.01205577,  0.00141083, -0.02327669,\n",
       "         -0.04379898, -0.04719068],\n",
       "        [ 0.03492767, -0.04413733,  0.00819557, -0.04310045,\n",
       "         -0.00631473, -0.03526009,  0.02300333,  0.03341332,\n",
       "          0.01857002, -0.03368495],\n",
       "        [ 0.0315528 , -0.03684436, -0.02680424,  0.00198674,\n",
       "         -0.025009  , -0.02826208,  0.03172994,  0.02685961,\n",
       "          0.01890923,  0.02135355],\n",
       "        [ 0.04441791, -0.0357502 ,  0.0117896 ,  0.04534895,\n",
       "          0.00688404, -0.01135522,  0.01884094, -0.03454997,\n",
       "         -0.03551066, -0.02939522]],\n",
       "\n",
       "       [[-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.01406127, -0.02260454, -0.04782575,  0.03460795,\n",
       "         -0.02924758, -0.0309129 , -0.04130355, -0.03885825,\n",
       "         -0.00180948, -0.00512154],\n",
       "        [-0.03585949,  0.00090118, -0.00146252,  0.00295174,\n",
       "         -0.01670665, -0.02147098,  0.02175012,  0.04716216,\n",
       "         -0.02851428, -0.00375961],\n",
       "        [ 0.00350571,  0.03550488, -0.01386068,  0.02051118,\n",
       "          0.00351199,  0.00862763, -0.04403657, -0.00613291,\n",
       "          0.03911482, -0.01636659],\n",
       "        [-0.00555509,  0.03944787, -0.04321172, -0.04466561,\n",
       "         -0.04996927,  0.01034564, -0.04451358,  0.00952385,\n",
       "          0.00185858,  0.04952911],\n",
       "        [ 0.0489543 , -0.04599167, -0.02180997, -0.00255345,\n",
       "         -0.00073596, -0.04046323,  0.01214548, -0.04406611,\n",
       "          0.03939415,  0.00471433]],\n",
       "\n",
       "       [[-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.01406127, -0.02260454, -0.04782575,  0.03460795,\n",
       "         -0.02924758, -0.0309129 , -0.04130355, -0.03885825,\n",
       "         -0.00180948, -0.00512154],\n",
       "        [-0.03585949,  0.00090118, -0.00146252,  0.00295174,\n",
       "         -0.01670665, -0.02147098,  0.02175012,  0.04716216,\n",
       "         -0.02851428, -0.00375961],\n",
       "        [ 0.00350571,  0.03550488, -0.01386068,  0.02051118,\n",
       "          0.00351199,  0.00862763, -0.04403657, -0.00613291,\n",
       "          0.03911482, -0.01636659],\n",
       "        [-0.00555509,  0.03944787, -0.04321172, -0.04466561,\n",
       "         -0.04996927,  0.01034564, -0.04451358,  0.00952385,\n",
       "          0.00185858,  0.04952911],\n",
       "        [ 0.03766884, -0.04648221, -0.04022791,  0.04386369,\n",
       "         -0.00583044,  0.04599324, -0.02037382,  0.03936739,\n",
       "          0.00853605,  0.01081951]],\n",
       "\n",
       "       [[-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [ 0.01282987,  0.00971548, -0.02846456,  0.04889705,\n",
       "         -0.02711152, -0.03835737, -0.0485883 , -0.0440638 ,\n",
       "         -0.04258186,  0.04962656],\n",
       "        [-0.01965251,  0.03135104,  0.01402876,  0.01379016,\n",
       "         -0.03591919, -0.01205577,  0.00141083, -0.02327669,\n",
       "         -0.04379898, -0.04719068],\n",
       "        [-0.0345405 ,  0.00256702, -0.01070974,  0.03959483,\n",
       "          0.03623655,  0.03407444,  0.00902761, -0.04305836,\n",
       "         -0.03814255,  0.02074486],\n",
       "        [ 0.0315528 , -0.03684436, -0.02680424,  0.00198674,\n",
       "         -0.025009  , -0.02826208,  0.03172994,  0.02685961,\n",
       "          0.01890923,  0.02135355],\n",
       "        [-0.01212652, -0.01686392, -0.03309673, -0.01813697,\n",
       "         -0.01693746, -0.03337439,  0.01675986, -0.02463887,\n",
       "          0.00037874, -0.00758417]],\n",
       "\n",
       "       [[-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.01915671,  0.04688672,  0.00269531,  0.00131109,\n",
       "         -0.02869274, -0.01230245,  0.03193055,  0.03414961,\n",
       "          0.04993803, -0.03114197],\n",
       "        [ 0.02782233,  0.00808592,  0.01275421,  0.01632525,\n",
       "          0.00967259,  0.00805169, -0.02289465, -0.03444273,\n",
       "          0.0476079 ,  0.02683834],\n",
       "        [ 0.00802984, -0.0246159 ,  0.03169036,  0.04827509,\n",
       "         -0.01076369, -0.02136768,  0.03309462,  0.00487251,\n",
       "          0.02011403,  0.04329355],\n",
       "        [-0.00555509,  0.03944787, -0.04321172, -0.04466561,\n",
       "         -0.04996927,  0.01034564, -0.04451358,  0.00952385,\n",
       "          0.00185858,  0.04952911]]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8ffd2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0, 9917, 6216, 1029, 5327], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6cc00a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.03427273,  0.04586866,  0.00929971, -0.04792982,\n",
       "          0.02398277,  0.02328685, -0.03871827,  0.02580975,\n",
       "          0.04588839, -0.00742799],\n",
       "        [-0.01965251,  0.03135104,  0.01402876,  0.01379016,\n",
       "         -0.03591919, -0.01205577,  0.00141083, -0.02327669,\n",
       "         -0.04379898, -0.04719068],\n",
       "        [-0.02825204,  0.01457674,  0.00036437,  0.0441901 ,\n",
       "          0.03212296, -0.03848406,  0.04848189, -0.0336314 ,\n",
       "          0.02269825, -0.03881244],\n",
       "        [ 0.0315528 , -0.03684436, -0.02680424,  0.00198674,\n",
       "         -0.025009  , -0.02826208,  0.03172994,  0.02685961,\n",
       "          0.01890923,  0.02135355],\n",
       "        [ 0.03876119,  0.02237042,  0.02382977, -0.03579959,\n",
       "          0.04280735, -0.00099518,  0.02244296, -0.0286389 ,\n",
       "         -0.01909524,  0.00037252]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "model.predict(np.expand_dims(embedded_docs[0], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60626de4",
   "metadata": {},
   "source": [
    "# Using WORD2VEC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138d8759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6c891bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "input_ids = torch.tensor([2,3,5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5564614d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size,output_dim)\n",
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3833265b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78868d33",
   "metadata": {},
   "source": [
    "# Using GPT-3 Vector dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e91dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size,output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b650347c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktokenNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached tiktoken-0.11.0-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Using cached regex-2025.9.18-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\aman\\miniconda3\\envs\\ptorch\\lib\\site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\aman\\miniconda3\\envs\\ptorch\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aman\\miniconda3\\envs\\ptorch\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aman\\miniconda3\\envs\\ptorch\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aman\\miniconda3\\envs\\ptorch\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2025.8.3)\n",
      "Using cached tiktoken-0.11.0-cp310-cp310-win_amd64.whl (884 kB)\n",
      "Using cached regex-2025.9.18-cp310-cp310-win_amd64.whl (276 kB)\n",
      "Installing collected packages: regex, tiktoken\n",
      "\n",
      "   ---------------------------------------- 0/2 [regex]\n",
      "   ---------------------------------------- 2/2 [tiktoken]\n",
      "\n",
      "Successfully installed regex-2025.9.18 tiktoken-0.11.0\n"
     ]
    }
   ],
   "source": [
    "%pip install tiktoken\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05d080f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaderV1(txt,batch_size=4,max_length=256,stride=128,shuffle=True,drop_last=True,num_workers=0):\n",
    "    # Intializing the tokenizer \n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Creating dataset\n",
    "    dataset = GPTDatasetV1(txt,tokenizer,max_length,stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_sizev= batch_size,\n",
    "        shuffle = shuffle,\n",
    "        drop_last = drop_last,\n",
    "        num_workers = num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff673575",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self,txt,tokenizer,max_length,stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt,allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0,len(token_ids)-max_length,stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i+1,i+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__self(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.input_ids[index],self.target_ids[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ad2f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a6331a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49bc72f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d0ff1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
